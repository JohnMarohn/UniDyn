%!TEX root = UniDyn-doc.tex

% \cite{Slichter1990}
%
%   Differential equation approach.
%
% ====================
%
% \cite{Shriver1991oct} = NMR product operator calculations ... 
% \cite{Guntert1993jan} = POMA = Product operator ...
% \cite{Guntert2006aug} = Symbolic NMR Product Operator Calculations 
%
%   Repeated application of a small number of rules for weakly-coupled I = 1/2 spins.
%
% \cite{Rodriguez2001oct} = Density matrix calculations in Mathematica
%
%   Two spin 1/2 particles, 4 x 4 matrix, added gradient
%
% \cite{Anand2007dec} = Simulation of steady-state {NMR} of coupled systems using Liouville
%	space and computer algebra methods
%
%   Multiple spins, steady-state solutions of LvN equation with relaxation.
%
% \cite{Jerschow2005sep} = MathNMR: Spin and spatial tensor manipulations in Mathematica
%
% 	Significant extension; move beyond weakly coupled spins and introduce spatial rotations
%   as well.  Must specify total spin angular momentum for each spin.  "Semi-symbolic".
%
% \cite{Filip2010nov} = SD-CAS: Spin Dynamics by Computer Algebra Systems
%
%	Algorithms developed for algebraically calculating products and commutators of expressions 
%   involving products of many spin operators.  
%
% \cite{Loke2011oct} = An efficient quantum circuit analyser on qubits and qudits
%
% 	"The CUGates notebook simulates arbitrarily complex quantum circuits comprised of
%	single/multiple qubit and qudit quantum gates.  It utilizes an irreducible form of
%   matrix decomposition for a general controlled gate with multiple conditionals and
%	is highly efficient in simulating complex quantum circuits." 
%
% ====================
% 
% \cite{Untidt2002jan} = Closed solution to the Baker-Campbell-Hausdorff problem: Exact 
%	effective Hamiltonian theory for analysis of nuclear-magnetic-resonance experiments
%
%	For spins, the matrices appearing in the propagator are finite and the propagator can be
%   expanded using the Cayley-Hamilton theorem.  Products of propagators can be combined using
%   the Baker-Campbell-Hausdorff, which for small numbers of spins also contains only a finite 
%   number of terms.   Goal: an effective Hamiltonian.
%
% \cite{Weyrauch2009sep} = Computing the Baker?Campbell?Hausdorff series and the Zassenhaus product
%
%	Evaluate different algorithms for writing the propagator.
%
% ====================
%
% \cite{Beskrovnyi1998jun} = Applying Mathematica to the analytical solution of the 
% 	nonlinear Heisenberg operator equations
%
% \cite{Nguyen1998dec} = Symbolic calculations of unitary transformations in quantum dynamics
%
%	Unitary transformations are represented by a truncated, finite series of nested commutators 
%	involving the generator.  Nguyen et al. described a procedure for resumming the subseries
%   to give a closed-form expression; we have tried this approach and find it to fail when the
%   arguments of the sines, cosines, and exponentials involve non-simple expressions such as
%   fractions.  Beskrovnyi1 was interested in a few coupled multiple oscillators, field modes. 
%   Same approach, but with multiple modes. 
%
% ==============
%
% \cite{Weatherford2004oct} = Symbolic calculation in chemistry: Selected examples
%
%	A wide but shallow review
%
% ==============
%
% Large packages:
%
% \cite{Helton2015feb} = NCAlgebra; impressive 
%
% \cite{Levitt2015mar} = SpinDynamica; wow ...
%
% ==============

\cite{Helton2015feb} \cite{Levitt2015mar}

Given a time-independent Hamiltonian ${\cal H}$ and an initial (density) operator $\rho(0)$, the \VerbFcn{Evolver} algorithm described below implements the following unitary rotation:
\begin{equation}
\rho(t) 
	= e^{-i {\cal H} t} \: \rho(0) \: e^{+i {\cal H} t}
	\equiv \text{\VerbFcn{Evolver}}[{\cal H},t,\rho(0)]
	\label{Eq:Evolve}
\end{equation}
Knowing the commutation relations among the operators comprising ${\cal H}$ and $\rho(0)$, it is often possible to obtain a closed-form algebraic solution to Eq.~\ref{Eq:Evolve}.  The \VerbFcn{Evolver} algorithm obtains a closed-form solution to Eq.~\ref{Eq:Evolve} using an algorithm built on an approach described by Slichter in Section 2.3 of his \emph{Principles of Magnetic Resonance} text \cite{Slichter1990}.

Slichter was interested in calculating the unitary evolution of angular momentum operators arising in spin-physics problems.  Below we introduce the Slichter procedure by considering a few representative examples.  We show that his procedure works remarkably well for calculating the unitary evolution in other cases as well --- calculating the time evolution of position and momentum operators evolving under the harmonic-oscillator Hamiltonian, for example.  It will become apparent that automating Slichter's procedure in a computer algebra program like \emph{Mathematica} is possible but challenging.  We introduce a generalization of the Slichter algorithm that is well suited for automation by a computer algebra program.  We have implemented this algorithm as a \emph{Mathematica} function, \VerbFcn{Evolver}.  This function evaluates Eq.~\ref{Eq:Evolve} given an ${\cal H}$, a $\rho(0)$, and the commutation relations between the operators comprising ${\cal H}$ and $\rho(0)$.

To understand the \VerbFcn{Evolver} algorithm it is essential to understand Slichter's approach to calculating the unitary evolution of an operator.  To help the reader understand and appreciate Slichter's approach, let us briefly review two methods commonly used for solving Eq.~\ref{Eq:Evolve}.  As an example, consider the case where ${\cal H} = \omega I_z$ and $\rho(0) = I_{+} = I_x + i \, I_y$.  In this case we want to compute
\begin{equation}
\rho(t) 
	= e^{-i \, \omega t \, I_z} \, I_{+} \, e^{+i \, \omega t \, I_z}.
	\label{Eq:I+rot}
\end{equation}

\myparagraph{Method 1}  One approach to computing $\rho(t)$ is to expand Eq.~\ref{Eq:I+rot} in a Taylor series,
\begin{equation}
\rho(t) 
	= \rho(0) + \rho^{(1)}(0) \, t + \frac{1}{2!} \rho^{(2)}(0) \, t^2
 		+ \frac{1}{3!} \rho^{(3)}(0) \, t^3 + \cdots
\end{equation}
The coefficients are obtained by differentiating $\rho$ and setting $t \rightarrow 0$.  Taking the first derivative,
\begin{subequations}
\begin{align}
\rho^{(1)}(t) 
	& = e^{-i \, \omega t \, I_z} \,
		(-i \, \omega \, I_z) \, I_{+} 
		e^{+i \, \omega t \, I_z}
	 + e^{-i \, \omega t \, I_z} \,
		 I_{+} (+i \, \omega \, I_z) \, 
		e^{+i \, \omega t \, I_z} \\
	& = e^{-i \, \omega t \, I_z} \, 
		(-i \, \omega [I_z,I_{+}] ) 
		\, e^{+i \, \omega t \, I_z} \\
\rho^{(1)}(0) & = -i \, \omega \, I_{+}
\end{align}
\end{subequations}
where $\rho^{(n)}$ represents the $n^{\text{th}}$ derivative with respect to time and where we have used $[I_z,I_{+}] = I_{+}$ to simplify the commutator.  Taking the second derivative,
\begin{subequations}
\begin{align}
\rho^{(2)}(t) & = e^{-i \, \omega t \, I_z} \, 
	((-i \, \omega)^2 [I_z,[I_z,I_{+}]] ) 
	\, e^{+i \, \omega t \, I_z} \\
\rho^{(2)}(0) & = (-i \, \omega)^2 \, I_{+} 
\end{align}
\end{subequations}
By induction, we see that
\begin{equation}
\rho^{(n)}(0) = (-i \, \omega)^n \, I_{+}
\end{equation}
Substituting this finding into the Taylor expansion gives
\begin{equation}
\rho(t) 
	= I_{+} \left( 1 
		+ (-i \, \omega \, t) 
		+ \frac{1}{2!} (-i \, \omega t)^2 
		+ \frac{1}{3!} (-i \, \omega t)^3
		+ \cdots
	\right)
\end{equation}
We are now supposed to recognize the term in parenthesis as the Taylor series of $e^{-i \, \omega \, t}$.  This insight enables us to resum the infinite series in the Taylor expansion to obtain the closed-form result
\begin{equation}
\rho(t) 
	= I_{+} \, e^{-i \, \omega \, t}.
	\label{Eq:I+-soln-method-1}
\end{equation}   

\myparagraph{Method 2} A second approach to evaluating Eq.~\ref{Eq:I+rot} is to expand the exponential using the L\"{o}wdin projection-operator theorem \cite{Lowdin1955mar}.  This theorem allows us to expand a function of an operator --- $I_z$ here --- in terms involving the function evaluated at the operator's eigenvalues times an operator that project's onto the eigenvalue's subspace.  Taking the total spin angular momentum to be $I = 1/2$ for simplicity, the relevant eigenvalues are $+1/2$ and $-1/2$ and the relevant projection operators are ${\cal P}_{1/2} = \ket{\alpha}\bra{\alpha}$ and ${\cal P}_{-1/2} = \ket{\beta}\bra{\beta}$.  Applying L\"{o}wdin's theorem,
\begin{equation}
e^{-i \, \omega t \, I_z} 
	= e^{-i \, \omega t / 2} \ket{\alpha}\bra{\alpha}
	+ e^{+i \, \omega t / 2} \ket{\beta}\bra{\beta}.
\end{equation}
Substituting this result into Eq.~\ref{Eq:I+rot} yields
\[
\rho(t) = \left( e^{-i \, \omega t / 2} \ket{\alpha}\bra{\alpha}
	+ e^{+i \, \omega t / 2} \ket{\beta}\bra{\beta} \right)
	I_{+} \left( e^{+i \, \omega t / 2} \ket{\alpha}\bra{\alpha}
	+ e^{-i \, \omega t / 2} \ket{\beta}\bra{\beta} \right)
\]
Applying the relations $I_{+} \ket{\alpha} = 0$, $I_{+} \ket{\beta} = \ket{\alpha}$, $\braket{\alpha|\alpha} = 1$, $\braket{\beta|\alpha} = 0$, and $\ket{\alpha} \bra{\beta} = I_{+}$, this expression simplifies to
\begin{equation}
\rho(t) 
	= I_{+} \, e^{-i \, \omega \, t}.
	\label{Eq:I+-soln-method-2}
\end{equation} 

While both these approaches yield closed-form solutions, each is hardly extensible.  The first method requires the resumming of a Taylor series; this step would be difficult or impossible to automate for any evolution more complicated that the one above.  The second method requires obtaining the eigenvalues of the Hamiltonian, usually by reducing it to matrix form and diagonalizing it.  It is hard to see how to apply this diagonalization procedure in an infinite-level system like the idealized harmonic oscillator. Even for a spin problem where the number of levels is finite, diagonalizing ${\cal H}$ would force us to write down the matrix representation of ${\cal H}$ which would in turn commit us to specifying the total angular momentum $I$ of the spin we are interested in.  In many problems, we would to obtain a solution valid for a spin of \emph{any} $I$.  

\myparagraph{Method 3, Example 1} Now consider Slichter's procedure. Let us take another look at the derivative of $\rho$:
\begin{subequations}  
\begin{align}
\dot{\rho}(t)
	& = e^{-i \, \omega t \, I_z} \: 
		(-i \, \omega [I_z,I_{+}] ) 
		\: e^{+i \, \omega t \, I_z} 
		\label{Eq:I+rot-(a)} \\
	& = -i \, \omega \left( 
			e^{-i \, \omega t \, I_z} \: I_{+} \: e^{+i \, \omega t \, I_z} 
		\right)
		\label{Eq:I+rot-(b)}
\end{align}
\end{subequations} 
As before we have used $[I_z,I_{+}] = I_{+}$ to reduce the commutator in Eq.~\ref{Eq:I+rot-(a)}.  The key insight in the Slichter procedure is that the term in parenthesis in Eq.~\ref{Eq:I+rot-(b)} is nothing more than the original time dependent density operator, $\rho(t)$.  This insight allows us to write Equation~\ref{Eq:I+rot-(b)} as
\begin{equation}
\dot{\rho}(t) 
	= -i \, \omega \, \rho(t)
	\label{Eq:Eq:I+rot-ODE}
\end{equation}
In this differential equation, $\omega$ is a \emph{number}, while $\rho(t)$ is an \emph{operator}.  The solution to this differential equation is
\begin{equation}
\rho(t) 
	= \rho(0) \, e^{-i \, \omega t}
 	= I_{+} \, e^{-i \, \omega t},
	\label{Eq:I+rot-soln}
\end{equation}
which is easily verified by back substitution. 

\myparagraph{Example 2} An analogous calculation arises in a harmonic oscillator problem where the Hamiltonian is ${\cal H} = \omega (a^{\dagger} a + 1/2)$ and the initial operator is $\rho(0) = a^{\dagger}$: 
\begin{equation}
\rho(t) 
	= e^{-i \omega t (a^{\dagger} a + 1/2)} 
		\, a^{\dagger} 
		\, e^{+i \omega t (a^{\dagger} a + 1/2)}
		\label{Eq:adaggerrot-soln}
\end{equation}
Using the same procedure and the commutation relation $[a^{\dagger} a,a^{\dagger}] = a^{\dagger} [a, a^{\dagger}] + [a^{\dagger}, a^{\dagger}] a = a^{\dagger}$, this equation reduces to 
\begin{equation}
	\rho(t)  = a^{\dagger} e^{-i \: \omega t}.
\end{equation}

These first two Slichter-procedure example cases have in common that the commutator of the Hamiltonian with the operator of interest is simply proportional to the operator. As a result of this underlying commutation relation, the problem of calculating Eq.~\ref{Eq:Evolve} in both cases has been reduced to the problem of solving a first-order differential equation, Eq.~\ref{Eq:Eq:I+rot-ODE}.  In light of the two previous methods, the Slichter procedure is rather remarkable.  It allows us to obtain a closed-form solution for Eq.~\ref{Eq:I+rot} without resorting to Taylor series and without even requiring knowledge of the Hamiltonian's eigenvalues.    

\myparagraph{Example 3} The Slichter procedure is readily applied to more complicated unitary-evolution problems.  Consider the case where ${\cal H} = \omega I_z$ and $\rho(0) = I_x$.  Then
\begin{equation}
\rho(t) 
	= e^{-i \, \omega t \, I_z} \: I_x \: e^{+i \, \omega t \, I_z}.
	\label{Eq:Ixrot}
\end{equation}
Taking the time derivative we obtain
\begin{subequations}  
\begin{align}
\dot{\rho}(t)
	& = e^{-i \, \omega t \, I_z} \: 
		(-i \, \omega [I_z,I_x] ) 
		\: e^{+i \, \omega t \, I_z} 
		\label{Eq:Ixrot-(a)} \\
	& = \omega \left( 
			e^{-i \, \omega t \, I_z} \: I_y \: e^{+i \, \omega t \, I_z} 
		\right)
		\label{Eq:Ixrot-(b)}
\end{align}
\end{subequations} 
where we have used $[I_z,I_x] = i \, I_y$ to reduce the commutator in Eq.~\ref{Eq:Ixrot-(a)}.  In contrast to the previous case, $\dot{\rho}(t)$ is not proportional to $\dot{\rho}$.  Taking another time derivative we obtain
\begin{subequations}  
\begin{align}
\ddot{\rho}(t)
	& = \omega \, e^{-i \, \omega t \, I_z} \: 
		(-i \, \omega [I_z,I_y] ) 
		\: e^{+i \, \omega t \, I_z} 
		\label{Eq:Ixrot-(c)} \\
	& = - \omega^2 \left( 
			e^{-i \, \omega t \, I_z} \: I_x \: e^{+i \, \omega t \, I_z} 
		\right)
		\label{Eq:Ixrot-(d)}
\end{align}
\end{subequations} 
where we have used $[I_z,I_y] = -i \, I_x$ to reduce the commutator in Eq.~\ref{Eq:Ixrot-(a)}. The term in parenthesis in Eq.~\ref{Eq:Ixrot-(d)} is proportional to $\rho(t)$ and consequently
\begin{equation}
\ddot{\rho}(t) = - \omega^2 \, \rho(t). \label{Eq:Ixrot-ODE}
\end{equation}
The solution to this second-order differential equation is
\begin{equation}
\rho(t) = \rho(0) \, \sin{(\omega t)} + \frac{\dot{\rho}(0)}{\omega} \, \cos{(\omega t)}.
\end{equation}
We are given that $\rho(0) = I_x$ and we see from Eq.~\ref{Eq:Ixrot-(b)} that $\dot{\rho}(0) = \omega \, I_y$.  Plugging these initial conditions into the above equation we obtain
\begin{equation}
\rho(t) 
	= I_x \, \sin{(\omega t)} + I_y \, \cos{(\omega t)}
	\label{Eq:Ixrot-soln}
\end{equation}
as the solution to Eq.~\ref{Eq:Ixrot}.

We can imagine automating the steps leading to Eqs.~\ref{Eq:I+rot-soln}, \ref{Eq:adaggerrot-soln}, and \ref{Eq:Ixrot-soln}.   What is required is the ability to
\begin{enumerate}

\item perform non-commutative algebra, 

\item evaluate commutators, and

\item determine which differential equation an evolved operator satisfies.

\end{enumerate}
\emph{Mathematica} has a native function for carrying out non-commutative multiplication, but this function has essentially no simplification rules associated with it; for example,
\begin{Verbatim}[xleftmargin=0.25in]
In[1] := a ** (2 b) // Simplify
Out[1] = a ** (2 b)
\end{Verbatim}
This limitation was resolved beautifully by Helton and co-workers, whose \verb+NCALgebra+ package \cite{Helton2015feb} gives \emph{Mathematica} the ability to manipulate non-commuting algebraic expressions.  This package allows the user to define variables as either commuting (e.g., $\omega$) or non-commuting (e.g., $I_+$, $I_x$, $a^{\dagger}$, and so on).  As we will show below, this package forms an excellent starting point for writing rules to expand and simplify commutators.  

Based on our experience so far, developing an algorithm capable of self-deriving Eqs.~\ref{Eq:I+rot-soln}, \ref{Eq:adaggerrot-soln}, and \ref{Eq:Ixrot-soln} would now seem to be a matter of calculating
\begin{align}
\rho^{(1)} & = U^{\dagger} \, [-i {\cal H}, \rho(0)] \, U \\
\rho^{(2)} & = U^{\dagger} \, [-i {\cal H}, [-i {\cal H}, \rho(0)]] \, U
	= U^{\dagger} \, [-i {\cal H}, \rho^{(1)}] \, U
\end{align}
and continuing until we obtain an expression that is proportional to $\rho = U^{\dagger} \, \rho(0) \, U$. If $n$ iterations are required, then $\rho(t)$ must satisfy an $n^\text{th}$ order differential equation.  If the equation's coefficients and initial conditions can be extracted from the  available non-commutative expressions correctly, then the differential equation can be fed to \emph{Mathematica} to solve.  This is roughly the procedure we will use.  Because it would have to handle solving a large number of possible differential equations, however, significant effort would be required to implement the procedure just outlined in a automated way.  The next example highlights why this is so.  This example will serve as our launching point for introducing a revised, simple, and general algorithm for implementing the Slichter procedure for evaluating unitary evolution in an automated way. 

\myparagraph{Example 4} Consider a unitary evolution with ${\cal H} = \Delta \omega I_z + \omega_1 I_x$ and $\rho(0) = I_z$.  This rotation is involved in calculating the evolution of the difference in populations of a two level system when near-resonant irradiation is applied.  The two-level system could be, for example, a spin $I = 1/2$ particle like a proton spin in a magnetic resonance experiment or it could be the lowest two electronic energy levels of an atom in a quantum optics experiment.  The unitary evolution we are interested in computing is
\begin{equation}
\rho(t)
	= e^{-i \, (\Delta \omega I_z + \omega_1 I_x) \, t}
	  \, I_z \,
	 e^{+i \, (\Delta \omega I_z + \omega_1 I_x) \, t}
	\equiv U^{\dagger} \, I_{x} \, U
	\label{Eq:Example4}  
\end{equation}
Computing the first few derivatives, we find
\begin{subequations}
\begin{align}
\dot{\rho} & = U^{\dagger} \, 
	\big( 
		-i [\Delta \omega I_z + \omega_1 I_x, I_z]
	\big) \, U \\
	& = U^{\dagger} \big( 
		-\omega_1 I_y 
	\big) U \\
\ddot{\rho} & = U^{\dagger} \, 
	\big(  
		-i [\Delta \omega I_z + \omega_1 I_x, -\omega_1, I_y]
	\big) \, U \\
	& = U^{\dagger} \big( 
		\Delta \omega \, \omega_1 I_x - \omega_1^2 I_z 
	\big) U \\
\dddot{\rho} & = U^{\dagger} \, 
	\big(  
		-i [\Delta \omega I_z + \omega_1 I_x, -\omega_1, 
				\Delta \omega \, \omega_1 I_x - \omega_1^2 I_z]
	\big) \, U \\
	& = U^{\dagger} \big( 
		\omega_1 \left( 
			\omega_1^2 + \Delta \omega^2
		\right) I_y
	\big) U
\end{align}
\end{subequations} 
Neither $\dot{\rho}$ nor $\ddot{\rho}$ is proportional to $\rho$.    We see, however, that $\dddot{\rho}$ is proportional to $\dot{\rho}$.  Defining $\sigma \equiv \dot{\rho}$, we see that $\sigma$ satisfies the following differential equation
\begin{equation}
\ddot{\sigma} 
	= - (\Delta \omega^2 + \omega_1^2) \, \sigma
	\label{Eq:Example4-ODE}
\end{equation}
with initial conditions
\begin{subequations}
\begin{align}
\sigma(0) 
	& = \dot{\rho}(0) 
	  = - \omega_1 I_y \\
\dot{\sigma}(0) 
	& = \ddot{\rho}(0)
	  = \Delta \omega \, \omega_1 I_x - \omega_1^2 I_z 
\end{align}
\end{subequations}
The solution to Eq.~\ref{Eq:Example4-ODE} is
\begin{equation}
\sigma(t) 
	= \sigma(0) \cos{(\omega_{\text{eff}} t)}
	+ \frac{\dot{\sigma}(0)}{\omega_{\text{eff}}}
		\sin{(\omega_{\text{eff}} t)}
\end{equation}
with
\begin{equation}
\omega_{\text{eff}} \equiv \sqrt{\Delta\omega^2 + \omega_1^2}
\end{equation}
an effective evolution frequency.  Plugging in initial conditions,
\begin{equation}
\sigma(t) 
	= \frac{\Delta \omega \, \omega_1}{\omega_{\text{eff}}}
		I_x \sin{(\omega_{\text{eff}} \, t)}
	- \omega_1 I_y \cos{(\omega_{\text{eff}} \, t)}
	- \frac{\omega_1^2}{\omega_{\text{eff}}}
		I_z \sin{(\omega_{\text{eff}} \, t)}
\end{equation}
To obtain an equation for $\rho(t)$ we need to integrate this equation for $\sigma(t)$, taking care to include a constant of integration.  Noting that
\[
\int \cos{(\omega_{\text{eff}} \, t)} \, dt 
	= \frac{\sin{(\omega_{\text{eff}} \, t)}}
	       {\omega_{\text{eff}}}
\text{ and }
\int \sin{(\omega_{\text{eff}} \, t)} \, dt
	= - \frac{\cos{(\omega_{\text{eff}} \, t)}}
	       {\omega_{\text{eff}}},	       
\]
the solution for $\rho(t)$ becomes
\begin{equation}
\rho(t) 
	= - \frac{\Delta \omega \, \omega_1}{\omega_{\text{eff}}^2}
		I_x \sin{(\omega_{\text{eff}} \, t)}
	- \frac{\omega_1}{\omega_{\text{eff}}} 
		I_y \sin{(\omega_{\text{eff}} \, t)}
	+ \frac{\omega_1^2}{\omega_{\text{eff}}^2}
		I_z \cos{(\omega_{\text{eff}} \, t)}
	+ c
	\label{Eq:Example4-temp}
\end{equation}
The integration constant $c$ is determined by requiring the above equation to satisfy $\rho(0) = I_z$, the initial condition.  Solving for the integration constant,
\begin{equation}
c = \frac{\Delta\omega \, \omega_1}
         {\Delta\omega^2 + \omega_1^2} I_x
	+ \frac{\Delta\omega^2}
	       {\Delta\omega^2 + \omega_1^2} I_z
\end{equation}
Plugging this integration constant into Eq.~\ref{Eq:Example4-temp} we obtain the following solution for the density operator in Eq.~\ref{Eq:Example4}:
\begin{multline}
\rho(t) = \left( 
		\frac{\Delta\omega^2}
		     {\Delta\omega^2 + \omega_1^2} I_z
		+ \frac{\Delta\omega \, \omega_1}
		       {\Delta\omega^2 + \omega_1^2} I_x
	\right)
	+ 
	\frac{\omega_1}{\sqrt{\Delta\omega^2 + \omega_1^2}}
	\sin{(\sqrt{\Delta\omega^2 + \omega_1^2} \: t)}  
	\\ 
	+ 
	\left( 
		\frac{\omega_1^2}
		     {\Delta\omega^2 + \omega_1^2} I_z
		- \frac{\Delta\omega \, \omega_1}
		       {\Delta\omega^2 + \omega_1^2} I_x
	\right) 
	\cos{(\sqrt{\Delta\omega^2 + \omega_1^2} \: t)}.	
\end{multline}

We see in this example an answer for $\rho(t)$ that is markedly more complicated that in the previous examples, the solution to (essentially) a third order differential equation.  To uncover this differential equation, is was necessary to compare subsequent derivatives of $\rho(t)$ not to $\rho(0)$ but to $\dot{\rho}(0)$ instead.  Considering in total the four examples of unitary evolution considered so far, it would seem that any algorithm we develop needs to consider the possibility that the density operator satisfies a first, second, or even third-order differential equation. 

\myparagraph{Method 4} We now show by example that the single differential equation in each of these four cases can be reduced to a set of \emph{coupled first-order} differential equations --- a significant step towards making a simple automated, unitary evolution algorithm.  We would expect the four cases to each still require a decision on the number of coupled of equations required to solve for $\rho$ in each case.  Surprisingly, no decision is needed.  We will show that all four cases can be handled by a set of four coupled differential equations.  This is the essential new insight implemented here in the \VerbFcn{Evolver} algorithm. 

To understand the new method, consider transforming the second-order differential equation in Eq.~\ref{Eq:Ixrot-ODE} into two coupled first-order equations.  Let the two new variables be 
\begin{equation}
x_1 = \rho \text{ and } x_2 = \dot{\rho}.
\end{equation}
Taking the time derivative of each of these variables we obtain 
\begin{subequations}
\begin{align}
\dot{x}_1 & = \dot{\rho} = x_2, \text{ and} \\
\dot{x}_1 & = \ddot{\rho} = \omega^2 \rho = \omega^2 x_1.
\end{align}
\end{subequations}
It is apparent that these two variables satisfy the following set of coupled first order equations
\begin{equation}
\frac{d}{dt} \begin{bmatrix} x_2 \\ x_1 \end{bmatrix}
	= \begin{bmatrix} 0 & \omega^2 \\ 1 & 0 \end{bmatrix}
	  \begin{bmatrix} x_2 \\ x_1 \end{bmatrix}
\text{ with } 
\begin{bmatrix} x_2(0) \\ x_1(0) \end{bmatrix}
	=
	\begin{bmatrix} \omega \, I_{y} \\ I_{x} \end{bmatrix}. \label{Eq:Ixrot-2x2}
\end{equation}
Solving this set of coupled equations, we find $x_1(t) = \rho(t) = I_x \, \sin{(\omega t)} + I_y \, \cos{(\omega t)}$, the expected answer.  

What if we did not know how many coupled equations were necessary to solve the problem?  Let's consider what would happen if we guessed that three coupled equations were needed instead of two.
Defining
\begin{equation}
x_1 = \rho \text{ and } x_2 = \dot{\rho} \text{ and } x_3 = \ddot{\rho},
\end{equation}
and taking the time derivative gives
\begin{subequations}
\begin{align}
\dot{x}_1 & = \dot{\rho} = x_2, \\
\dot{x}_2 & = \ddot{\rho} = x_3, \text{ and} \\
\dot{x}_3 & = \dddot{\rho} \\
	& = \omega^2 \, U^{\dagger} \, (-i \, \omega [I_z,I_x] ) \, U \\
	& = \omega^3 \, U^{\dagger} \, I_{y} \, U \\
	& = \omega^2 \, \dot{\rho} \\
	& = \omega^2 \, x_2.
\end{align}
\end{subequations}
In writing $\dot{x}_3$ we have used the shorthand $U(t) \equiv e^{+i \, \omega t \, I_z}$ and employed Eq.~\ref{Eq:Ixrot-(b)} to simplify the result.  The three variables satisfy the following set of coupled first-order differential equations
\begin{equation}
\frac{d}{dt} \begin{bmatrix} x_3 \\ x_2 \\ x_1 \end{bmatrix}
	= \begin{bmatrix} 
	    0 & \omega^2 & 0 \\
		1 & 0 & 0 \\
		0 & 1 & 0
	  \end{bmatrix}
	  \begin{bmatrix} 
	  	x_3 \\ x_2 \\ x_1
	   \end{bmatrix}
\text{ with } 
\begin{bmatrix}
    x_3(0) \\
    x_2(0) \\ 
    x_1(0) 
 \end{bmatrix}
=
\begin{bmatrix}
	- \omega^2 \, I_{x} \\ 
	\omega \, I_{y} \\
	I_{x}
\end{bmatrix}
\end{equation}
Solving this new set of three coupled equations gives $x_1(t) = \rho(t) = I_x \, \sin{(\omega t)} + I_y \, \cos{(\omega t)}$ --- the \emph{same answer} that was obtained by solving the set of two coupled equations, Eqs.~\ref{Eq:Ixrot-2x2}.  This finding suggests that we are at liberty to ``overguess'' the number of equations required to solve the problem.

