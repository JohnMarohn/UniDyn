%!TEX root = ../UniDyn-doc.tex

To understand the \VerbFcn{Evolver} algorithm it is essential to understand Slichter's approach to calculating the unitary evolution of an operator.  To help the reader understand and appreciate Slichter's approach, let us briefly review two methods commonly used for solving Eq.~\ref{Eq:Evolve}.  As an example, consider the case where ${\cal H} = \omega I_z$ and $\rho(0) = I_{+} = I_x + i \, I_y$.  In this case we want to compute
\begin{equation}
\rho(t) 
	= e^{-i \, \omega t \, I_z} \, I_{+} \, e^{+i \, \omega t \, I_z}.
	\label{Eq:I+rot}
\end{equation}


% --------------------------
\subsection{Method 1}
% --------------------------

One approach to computing $\rho(t)$ is to expand Eq.~\ref{Eq:I+rot} in a Taylor series,
\begin{equation}
\rho(t) 
	= \rho(0) + \rho^{(1)}(0) \, t + \frac{1}{2!} \rho^{(2)}(0) \, t^2
 		+ \frac{1}{3!} \rho^{(3)}(0) \, t^3 + \cdots
\end{equation}
The coefficients are obtained by differentiating $\rho$ and setting $t \rightarrow 0$.  Taking the first derivative,
\begin{subequations}
\begin{align}
\rho^{(1)}(t) 
	& = e^{-i \, \omega t \, I_z} \,
		(-i \, \omega \, I_z) \, I_{+} 
		e^{+i \, \omega t \, I_z}
	 + e^{-i \, \omega t \, I_z} \,
		 I_{+} (+i \, \omega \, I_z) \, 
		e^{+i \, \omega t \, I_z} \\
	& = e^{-i \, \omega t \, I_z} \, 
		(-i \, \omega [I_z,I_{+}] ) 
		\, e^{+i \, \omega t \, I_z} \\
\rho^{(1)}(0) & = -i \, \omega \, I_{+}
\end{align}
\end{subequations}
where $\rho^{(n)}$ represents the $n^{\text{th}}$ derivative with respect to time and where we have used $[I_z,I_{+}] = I_{+}$ to simplify the commutator.  Taking the second derivative,
\begin{subequations}
\begin{align}
\rho^{(2)}(t) & = e^{-i \, \omega t \, I_z} \, 
	((-i \, \omega)^2 [I_z,[I_z,I_{+}]] ) 
	\, e^{+i \, \omega t \, I_z} \\
\rho^{(2)}(0) & = (-i \, \omega)^2 \, I_{+} 
\end{align}
\end{subequations}
By induction, we see that
\begin{equation}
\rho^{(n)}(0) = (-i \, \omega)^n \, I_{+}
\end{equation}
Substituting this finding into the Taylor expansion gives
\begin{equation}
\rho(t) 
	= I_{+} \left( 1 
		+ (-i \, \omega \, t) 
		+ \frac{1}{2!} (-i \, \omega t)^2 
		+ \frac{1}{3!} (-i \, \omega t)^3
		+ \cdots
	\right)
\end{equation}
We are now supposed to recognize the term in parenthesis as the Taylor series of $e^{-i \, \omega \, t}$.  This insight enables us to resum the infinite series in the Taylor expansion to obtain the closed-form result
\begin{equation}
\rho(t) 
	= I_{+} \, e^{-i \, \omega \, t}.
	\label{Eq:I+-soln-method-1}
\end{equation}   

% --------------------------
\subsection{Method 2} 
% --------------------------

A second approach to evaluating Eq.~\ref{Eq:I+rot} is to expand the exponential using the L\"{o}wdin projection-operator theorem \cite{Lowdin1955mar}, equivalent to the Cayley-Hamilton theorem \cite{Strang2016}.  This theorem allows us to expand a function of an operator --- $I_z$ here --- in terms involving the function evaluated at the operator's eigenvalues times an operator that project's onto the eigenvalue's subspace.  Taking the total spin angular momentum to be $I = 1/2$ for simplicity, the relevant eigenvalues are $+1/2$ and $-1/2$ and the relevant projection operators are ${\cal P}_{1/2} = \ket{\alpha}\bra{\alpha}$ and ${\cal P}_{-1/2} = \ket{\beta}\bra{\beta}$.  Applying L\"{o}wdin's theorem,
\begin{equation}
e^{-i \, \omega t \, I_z} 
	= e^{-i \, \omega t / 2} \ket{\alpha}\bra{\alpha}
	+ e^{+i \, \omega t / 2} \ket{\beta}\bra{\beta}.
\end{equation}
Substituting this result into Eq.~\ref{Eq:I+rot} yields
\[
\rho(t) = \left( e^{-i \, \omega t / 2} \ket{\alpha}\bra{\alpha}
	+ e^{+i \, \omega t / 2} \ket{\beta}\bra{\beta} \right)
	I_{+} \left( e^{+i \, \omega t / 2} \ket{\alpha}\bra{\alpha}
	+ e^{-i \, \omega t / 2} \ket{\beta}\bra{\beta} \right)
\]
Applying the relations $I_{+} \ket{\alpha} = 0$, $I_{+} \ket{\beta} = \ket{\alpha}$, $\braket{\alpha|\alpha} = 1$, $\braket{\beta|\alpha} = 0$, and $\ket{\alpha} \bra{\beta} = I_{+}$, this expression simplifies to
\begin{equation}
\rho(t) 
	= I_{+} \, e^{-i \, \omega \, t}.
	\label{Eq:I+-soln-method-2}
\end{equation} 

While both Methods 1 and 2 yield closed-form solutions, each is hardly extensible. 
Method 1 requires resumming a Taylor series; this step would be difficult or impossible to automate for any evolution more complicated than the one above.
Method 2 requires obtaining the eigenvalues of the Hamiltonian, by reducing it to matrix form and diagonalizing it.  
It is hard to see how to apply this procedure in an infinite-level system like the idealized harmonic oscillator.
For spin problems where the number of levels is finite, Method 2 still has serious limitations.
Diagonalizing ${\cal H}$ forces us to write down the matrix representation of ${\cal H}$ which in turn commits us to specifying the total angular momentum $I$ of the spin we are interested in.
An exponentiated matrix $A$ of the form $e^{i A}$ can be written, using the Cayley-Hamilton theorem \cite{Strang2016}, as a polynomial function of $A$ \cite{DeZela2014jun,Curtright2014aug}.
If $A$ is a spin angular-momentum operator, then $e^{i A}$ can be written as a sum over four Pauli matrices for $I = 1/2$ and as a sum over eight Gell-Mann matrices for $I = 1$ \cite{Gell-Mann1962feb,Bertlmann2008may,Curtright2015dec}.
In many problems, we would like to obtain a solution valid for a spin of \emph{any} $I$, and most interesting spin problems involve Hamiltonians more complicated than a spin angular-momentum operator.


% --------------------------
\subsection{Method 3} 
% --------------------------

Now consider Slichter's procedure \cite{Slichter1990}. 

\myparagraph{Example 1} Let us take another look at the derivative of $\rho$:
\begin{subequations}  
\begin{align}
\dot{\rho}(t)
	& = e^{-i \, \omega t \, I_z} \: 
		(-i \, \omega [I_z,I_{+}] ) 
		\: e^{+i \, \omega t \, I_z} 
		\label{Eq:I+rot-(a)} \\
	& = -i \, \omega \left( 
			e^{-i \, \omega t \, I_z} \: I_{+} \: e^{+i \, \omega t \, I_z} 
		\right)
		\label{Eq:I+rot-(b)}
\end{align}
\end{subequations} 
As before we have used $[I_z,I_{+}] = I_{+}$ to reduce the commutator in Eq.~\ref{Eq:I+rot-(a)}.  The key insight in the Slichter procedure is that the term in parenthesis in Eq.~\ref{Eq:I+rot-(b)} is nothing more than the original time-dependent density operator, $\rho(t)$.  This insight allows us to write Equation~\ref{Eq:I+rot-(b)} as
\begin{equation}
\dot{\rho}(t) 
	= -i \, \omega \, \rho(t)
	\label{Eq:Eq:I+rot-ODE}
\end{equation}
In this differential equation, $\omega$ is a \emph{number}, while $\rho(t)$ is an \emph{operator}.  The solution to this differential equation is
\begin{equation}
\rho(t) 
	= \rho(0) \, e^{-i \, \omega t}
 	= I_{+} \, e^{-i \, \omega t},
	\label{Eq:I+rot-soln}
\end{equation}
which is easily verified by back substitution. 

\myparagraph{Example 2} An analogous calculation arises in a harmonic oscillator problem where the Hamiltonian is ${\cal H} = \omega (a^{\dagger} a + 1/2)$ and the initial operator is $\rho(0) = a^{\dagger}$: 
\begin{equation}
\rho(t) 
	= e^{-i \omega t (a^{\dagger} a + 1/2)} 
		\, a^{\dagger} 
		\, e^{+i \omega t (a^{\dagger} a + 1/2)}
		\label{Eq:adaggerrot-soln}
\end{equation}
Using the same procedure and the commutation relation $[a^{\dagger} a,a^{\dagger}] = a^{\dagger} [a, a^{\dagger}] + [a^{\dagger}, a^{\dagger}] a = a^{\dagger}$, this equation reduces to 
\begin{equation}
	\rho(t)  = a^{\dagger} e^{-i \: \omega t}.
\end{equation}

These first two Slichter-procedure example cases have in common that the commutator of the Hamiltonian with the operator of interest is simply proportional to the operator. As a result of this underlying commutation relation, the problem of calculating Eq.~\ref{Eq:Evolve} in both cases has been reduced to the problem of solving a first-order differential equation, Eq.~\ref{Eq:Eq:I+rot-ODE}.  In light of the two previous methods, the Slichter procedure is rather remarkable.  It allows us to obtain a closed-form solution for Eq.~\ref{Eq:I+rot} without resorting to Taylor series and without even requiring knowledge of the Hamiltonian's eigenvalues.    

\myparagraph{Example 3} The Slichter procedure is readily applied to more complicated unitary-evolution problems.  Consider the case where ${\cal H} = \omega I_z$ and $\rho(0) = I_x$.  Then
\begin{equation}
\rho(t) 
	= e^{-i \, \omega t \, I_z} \: I_x \: e^{+i \, \omega t \, I_z}.
	\label{Eq:Ixrot}
\end{equation}
Taking the time derivative we obtain
\begin{subequations}  
\begin{align}
\dot{\rho}(t)
	& = e^{-i \, \omega t \, I_z} \: 
		(-i \, \omega [I_z,I_x] ) 
		\: e^{+i \, \omega t \, I_z} 
		\label{Eq:Ixrot-(a)} \\
	& = \omega \left( 
			e^{-i \, \omega t \, I_z} \: I_y \: e^{+i \, \omega t \, I_z} 
		\right)
		\label{Eq:Ixrot-(b)}
\end{align}
\end{subequations} 
where we have used $[I_z,I_x] = i \, I_y$ to reduce the commutator in Eq.~\ref{Eq:Ixrot-(a)}.  In contrast to the previous case, $\dot{\rho}(t)$ is not proportional to $\dot{\rho}$.  Taking another time derivative we obtain
\begin{subequations}  
\begin{align}
\ddot{\rho}(t)
	& = \omega \, e^{-i \, \omega t \, I_z} \: 
		(-i \, \omega [I_z,I_y] ) 
		\: e^{+i \, \omega t \, I_z} 
		\label{Eq:Ixrot-(c)} \\
	& = - \omega^2 \left( 
			e^{-i \, \omega t \, I_z} \: I_x \: e^{+i \, \omega t \, I_z} 
		\right)
		\label{Eq:Ixrot-(d)}
\end{align}
\end{subequations} 
where we have used $[I_z,I_y] = -i \, I_x$ to reduce the commutator in Eq.~\ref{Eq:Ixrot-(c)}. The term in parenthesis in Eq.~\ref{Eq:Ixrot-(d)} is proportional to $\rho(t)$ and, consequently,
\begin{equation}
\ddot{\rho}(t) = - \omega^2 \, \rho(t). \label{Eq:Ixrot-ODE}
\end{equation}
The solution to this second-order differential equation is
\begin{equation}
\rho(t) = \rho(0) \, \cos{(\omega t)} + \frac{\dot{\rho}(0)}{\omega} \, \sin{(\omega t)}.
\end{equation}
We are given that $\rho(0) = I_x$ and we see from Eq.~\ref{Eq:Ixrot-(b)} that $\dot{\rho}(0) = \omega \, I_y$.  Plugging these initial conditions into the above equation we obtain
\begin{equation}
\rho(t) 
	= I_x \, \cos{(\omega t)} + I_y \, \sin{(\omega t)}
	\label{Eq:Ixrot-soln}
\end{equation}
as the solution to Eq.~\ref{Eq:Ixrot}.

Based on our experience so far, developing an algorithm capable of self-deriving Eqs.~\ref{Eq:I+rot-soln}, \ref{Eq:adaggerrot-soln}, and \ref{Eq:Ixrot-soln} would now seem to be a matter of calculating
\begin{align}
\rho^{(1)} & = U^{\dagger} \, [-i {\cal H}, \rho(0)] \, U \\
\rho^{(2)} & = U^{\dagger} \, [-i {\cal H}, [-i {\cal H}, \rho(0)]] \, U
	= U^{\dagger} \, [-i {\cal H}, \rho^{(1)}] \, U
\end{align}
and continuing until we obtain an expression that is proportional to $\rho = U^{\dagger} \, \rho(0) \, U$. If $n$ iterations are required, then $\rho(t)$ must satisfy an $n^\text{th}$ order differential equation.  If the equation's coefficients and initial conditions can be extracted from the  available non-commutative expressions correctly, then the differential equation can be fed to \emph{Mathematica} to solve.  This is roughly the procedure we will use.  Because it would have to handle solving a large number of possible differential equations, however, significant effort would be required to implement the procedure just outlined in an automated way.  The next example highlights why this is so.  This example will serve as our launching point for introducing a revised, simple, and general algorithm for implementing the Slichter procedure for evaluating unitary evolution in an automated way. 

\myparagraph{Example 4} Consider a unitary evolution with ${\cal H} = \Delta \omega I_z + \omega_1 I_x$ and $\rho(0) = I_z$.  This rotation is involved in calculating the evolution of the difference in populations of a two level system when near-resonant irradiation is applied.  The two-level system could be, for example, a spin $I = 1/2$ particle like a proton spin in a magnetic resonance experiment or it could be the lowest two electronic energy levels of an atom in a quantum optics experiment.  The unitary evolution we are interested in computing is
\begin{equation}
\rho(t)
	= e^{-i \, (\Delta \omega I_z + \omega_1 I_x) \, t}
	  \, I_z \,
	 e^{+i \, (\Delta \omega I_z + \omega_1 I_x) \, t}
	\equiv U^{\dagger} \, I_{x} \, U
	\label{Eq:Example4}  
\end{equation}
Computing the first few derivatives, we find
\begin{subequations}
\begin{align}
\dot{\rho} & = U^{\dagger} \, 
	\big( 
		-i [\Delta \omega I_z + \omega_1 I_x, I_z]
	\big) \, U \\
	& = U^{\dagger} \big( 
		-\omega_1 I_y 
	\big) U \\
\ddot{\rho} & = U^{\dagger} \, 
	\big(  
		-i [\Delta \omega I_z + \omega_1 I_x, -\omega_1, I_y]
	\big) \, U \\
	& = U^{\dagger} \big( 
		\Delta \omega \, \omega_1 I_x - \omega_1^2 I_z 
	\big) U \\
\dddot{\rho} & = U^{\dagger} \, 
	\big(  
		-i [\Delta \omega I_z + \omega_1 I_x, -\omega_1, 
				\Delta \omega \, \omega_1 I_x - \omega_1^2 I_z]
	\big) \, U \\
	& = U^{\dagger} \big( 
		\omega_1 \left( 
			\omega_1^2 + \Delta \omega^2
		\right) I_y
	\big) U
\end{align}
\end{subequations} 
Neither $\dot{\rho}$ nor $\ddot{\rho}$ is proportional to $\rho$.    We see, however, that $\dddot{\rho}$ is proportional to $\dot{\rho}$.  Defining $\sigma \equiv \dot{\rho}$, we see that $\sigma$ satisfies the following differential equation
\begin{equation}
\ddot{\sigma} 
	= - (\Delta \omega^2 + \omega_1^2) \, \sigma
	\label{Eq:Example4-ODE}
\end{equation}
with initial conditions
\begin{subequations}
\begin{align}
\sigma(0) 
	& = \dot{\rho}(0) 
	  = - \omega_1 I_y \\
\dot{\sigma}(0) 
	& = \ddot{\rho}(0)
	  = \Delta \omega \, \omega_1 I_x - \omega_1^2 I_z 
\end{align}
\end{subequations}
The solution to Eq.~\ref{Eq:Example4-ODE} is
\begin{equation}
\sigma(t) 
	= \sigma(0) \cos{(\omega_{\text{eff}} t)}
	+ \frac{\dot{\sigma}(0)}{\omega_{\text{eff}}}
		\sin{(\omega_{\text{eff}} t)}
\end{equation}
with
\begin{equation}
\omega_{\text{eff}} \equiv \sqrt{\Delta\omega^2 + \omega_1^2}
\end{equation}
an effective evolution frequency.  Plugging in initial conditions,
\begin{equation}
\sigma(t) 
	= \frac{\Delta \omega \, \omega_1}{\omega_{\text{eff}}}
		I_x \sin{(\omega_{\text{eff}} \, t)}
	- \omega_1 I_y \cos{(\omega_{\text{eff}} \, t)}
	- \frac{\omega_1^2}{\omega_{\text{eff}}}
		I_z \sin{(\omega_{\text{eff}} \, t)}
\end{equation}
To obtain an equation for $\rho(t)$ we need to integrate this equation for $\sigma(t)$, taking care to include a constant of integration.  Noting that
\[
\int \cos{(\omega_{\text{eff}} \, t)} \, dt 
	= \frac{\sin{(\omega_{\text{eff}} \, t)}}
	       {\omega_{\text{eff}}}
\text{ and }
\int \sin{(\omega_{\text{eff}} \, t)} \, dt
	= - \frac{\cos{(\omega_{\text{eff}} \, t)}}
	       {\omega_{\text{eff}}},	       
\]
the solution for $\rho(t)$ becomes
\begin{equation}
\rho(t) 
	= - \frac{\Delta \omega \, \omega_1}{\omega_{\text{eff}}^2}
		I_x \sin{(\omega_{\text{eff}} \, t)}
	- \frac{\omega_1}{\omega_{\text{eff}}} 
		I_y \sin{(\omega_{\text{eff}} \, t)}
	+ \frac{\omega_1^2}{\omega_{\text{eff}}^2}
		I_z \cos{(\omega_{\text{eff}} \, t)}
	+ c
	\label{Eq:Example4-temp}
\end{equation}
The integration constant $c$ is determined by requiring the above equation to satisfy $\rho(0) = I_z$, the initial condition.  Solving for the integration constant,
\begin{equation}
c = \frac{\Delta\omega \, \omega_1}
         {\Delta\omega^2 + \omega_1^2} I_x
	+ \frac{\Delta\omega^2}
	       {\Delta\omega^2 + \omega_1^2} I_z
\end{equation}
Plugging this integration constant into Eq.~\ref{Eq:Example4-temp} we obtain the following solution for the density operator in Eq.~\ref{Eq:Example4}:
\begin{multline}
\rho(t) = \left( 
		\frac{\Delta\omega^2}
		     {\Delta\omega^2 + \omega_1^2} I_z
		+ \frac{\Delta\omega \, \omega_1}
		       {\Delta\omega^2 + \omega_1^2} I_x
	\right)
	+ 
	\frac{\omega_1}{\sqrt{\Delta\omega^2 + \omega_1^2}}
	\sin{(\sqrt{\Delta\omega^2 + \omega_1^2} \: t)}  
	\\ 
	+ 
	\left( 
		\frac{\omega_1^2}
		     {\Delta\omega^2 + \omega_1^2} I_z
		- \frac{\Delta\omega \, \omega_1}
		       {\Delta\omega^2 + \omega_1^2} I_x
	\right) 
	\cos{(\sqrt{\Delta\omega^2 + \omega_1^2} \: t)}.
	\label{Eq:example4-soln}	
\end{multline}

We see in this example an answer for $\rho(t)$ that is markedly more complicated that in the previous examples, the solution to a third order differential equation.  To uncover this differential equation, is was necessary to compare subsequent derivatives of $\rho(t)$ not to $\rho(0)$ but to $\dot{\rho}(0)$ instead.

Considering in total the four examples of unitary evolution enumerated so far, it would seem that any algorithm we develop needs to consider the possibility that the density operator satisfies a first, second, or even third-order differential equation.  
Before continuing, there is another case to consider.

\myparagraph{Example 5} Consider the unitary rotation
\begin{equation}
x^{\prime}  = 
  e^{-i \hbar^{-1} \, \delta x \, p}
  \, x \,
  e^{+i \hbar^{-1} \, \delta x \, p}
\end{equation}
which we can obtain from
\begin{equation}
\rho(\tau) = 
   e^{-i \hbar^{-1} \, \tau \, \delta x \, p}
     \, x \,
     e^{+i \hbar^{-1} \, \tau \, \delta x \, p}
\end{equation}
by setting the unitless parameter $\tau$ equal to $1$.
Computing the first two derivatives of $\rho$ with respect to $\tau$ we find
\begin{subequations}
\begin{align}
\dot{\rho} & =
  e^{-i \hbar^{-1} \, \tau \, \delta x \, p} 
  \left( -i \hbar^{-1} \, \delta x \, [p, x] \right) 
  e^{+i \hbar^{-1} \, \tau \, \delta x \, p} \\
  & = - \delta x \\
\ddot{\rho} & = 0 
\end{align}
\end{subequations}
where we have used that $[p, x] = -i \, \hbar$.
As in Examples 1 and 2, we have a first-order differential equation.
Here the relevant differential equation is simply $\dot{\rho}(\tau) = - \delta x$, with initial condition $\rho(0) = x$.
It follows that $\rho = x + \tau \, \delta{x}$ and
\begin{equation}
x^{\prime}  = x - \delta x.  \label{eq:translate-x}
\end{equation}
In a similar manner, we can obtain
\begin{equation}
p^{\prime}  = 
  e^{-i \hbar^{-1} \, \delta p \, x}
  \, p \,
  e^{+i \hbar^{-1} \, \delta p \, x}
  = p + \delta p
\end{equation}
From these examples, we recognize $\exp\!{\left( -i \hbar^{-1} \, \delta x \, p \right)}$ as the unitary transformation inducing a translation and $\exp\!{\left( -i \hbar^{-1} \, \delta p \, x \right)}$ as the unitary transformation inducing a momentum kick.

% --------------------------
\subsection{Method 4} 
% --------------------------

We now show by example that the single differential equation in each of these five cases can be reduced to a set of \emph{coupled first-order} differential equations --- a significant step towards making a simple automated, unitary evolution algorithm.  We would expect the five cases to each still require a decision on the number of coupled of equations required to solve for $\rho$ in each case.  Surprisingly, no decision is needed.  We will show that all the cases we have discussed so far can be handled by a set of four coupled differential equations.  This is the essential new insight implemented here in the \VerbFcn{Evolver1} algorithm. 

To understand the new method, consider transforming the second-order differential equation in Eq.~\ref{Eq:Ixrot-ODE} into two coupled first-order equations.  Let the two new variables be 
\begin{equation}
x_1 = \rho \text{ and } x_2 = \dot{\rho}.
\end{equation}
Taking the time derivative of each of these variables we obtain 
\begin{subequations}
\begin{align}
\dot{x}_1 & = \dot{\rho} = x_2, \text{ and} \\
\dot{x}_1 & = \ddot{\rho} = - \omega^2 \rho = - \omega^2 x_1.
\end{align}
\end{subequations}
It is apparent that these two variables satisfy the following set of coupled first order equations
\begin{equation}
\frac{d}{dt} \begin{bmatrix} x_2 \\ x_1 \end{bmatrix}
	= \begin{bmatrix} 0 & - \omega^2 \\ 1 & 0 \end{bmatrix}
	  \begin{bmatrix} x_2 \\ x_1 \end{bmatrix}
\text{ with } 
\begin{bmatrix} x_2(0) \\ x_1(0) \end{bmatrix}
	=
	\begin{bmatrix} \omega \, I_{y} \\ I_{x} \end{bmatrix}. \label{Eq:Ixrot-2x2}
\end{equation}
Solving this set of coupled equations, we find $x_1(t) = \rho(t) = I_x \, \sin{(\omega t)} + I_y \, \cos{(\omega t)}$, the expected answer.  

What if we did not know how many coupled equations were necessary to solve the problem?  Let's consider what would happen if we guessed that three coupled equations were needed instead of two.
Defining
\begin{equation}
x_1 = \rho \text{ and } x_2 = \dot{\rho} \text{ and } x_3 = \ddot{\rho},
\end{equation}
and taking the time derivative gives
\begin{subequations}
\begin{align}
\dot{x}_1 & = \dot{\rho} = x_2, \\
\dot{x}_2 & = \ddot{\rho} = x_3, \text{ and} \\
\dot{x}_3 & = \dddot{\rho} \\
	& = \omega^2 \, U^{\dagger} \, (-i \, \omega [I_z,I_x] ) \, U \\
	& = - \omega^3 \, U^{\dagger} \, I_{y} \, U \\
	& = - \omega^2 \, \dot{\rho} \\
	& = - \omega^2 \, x_2.
\end{align}
\end{subequations}
In writing $\dot{x}_3$ we have used the shorthand $U(t) \equiv \exp\!{\left( i \, \omega \, t \, I_z \right)}$ and employed Eq.~\ref{Eq:Ixrot-(b)} to simplify the result.  The three variables satisfy the following set of coupled first-order differential equations
\begin{equation}
\frac{d}{dt} \begin{bmatrix} x_3 \\ x_2 \\ x_1 \end{bmatrix}
	= \begin{bmatrix} 
	    0 & -\omega^2 & 0 \\
		1 & 0 & 0 \\
		0 & 1 & 0
	  \end{bmatrix}
	  \begin{bmatrix} 
	  	x_3 \\ x_2 \\ x_1
	   \end{bmatrix}
\text{ with } 
\begin{bmatrix}
    x_3(0) \\
    x_2(0) \\ 
    x_1(0) 
 \end{bmatrix}
=
\begin{bmatrix}
	- \omega^2 \, I_{x} \\ 
	\omega \, I_{y} \\
	I_{x}
\end{bmatrix}
\end{equation}
Solving this new set of three coupled equations gives $x_1(t) = \rho(t) = I_x \, \sin{(\omega t)} + I_y \, \cos{(\omega t)}$ --- the \emph{same answer} that was obtained by solving the set of two coupled equations, Eqs.~\ref{Eq:Ixrot-2x2}.  This finding suggests that we are at liberty to ``overguess'' the number of equations required to solve the problem.

Let us see how the new method would be applied to solve the Example 4 problem with ${\cal H} = \Delta \omega I_z + \omega_1 I_x$ and $\rho(0) = I_z$.  The time derivatives up to third order may be summarized as
\begin{equation}
\begin{bmatrix}
	\rho^{(3)} \\
	\rho^{(2)} \\
	\rho^{(1)} \\
	\rho^{(0)} 
\end{bmatrix}
=
U^{\dagger}
\begin{bmatrix}
	- \Delta\omega (\Delta\omega^2 + \omega_1^2) \, I_y \\
	-\Delta\omega \, (\Delta\omega \, I_x - \omega_1 I_z)  \\
	\Delta \omega \, I_y \\
	I_x 
\end{bmatrix}
U
\end{equation}
with $\rho^{(n)}$ the $n^{\text{th}}$ derivative of $\rho$ with respect to time and
\begin{equation}
U \equiv \exp\!{\left( i \, (\Delta \omega I_z + \omega_1 I_x) \, t \right)}.
\end{equation}
We see that $\rho^{(3)} = - (\Delta\omega^2 + \omega_1^2) \, \rho^{(1)}$, as we showed before.  Defining $x_n = \rho^{(n-1)}$ for $n = 1$ through $4$, we obtain the following set of four coupled equations describing the time evolution of the density operator:
\begin{equation}
\underbrace{
\frac{d}{dt} 
	\begin{bmatrix} 
		x_4 \\ x_3 \\ x_2 \\ x_1 
	\end{bmatrix}}_{\dot{\bm{\lambda}}}
	= \underbrace{\begin{bmatrix} 
	    0 & -(\Delta\omega^2 + \omega_1^2) & 0 & 0 \\
	    1 & 0 & 0 & 0 \\
		0 & 1 & 0 & 0 \\
		0 & 0 & 1 & 0
	  \end{bmatrix}}_{\bm{\Omega}}
	  \underbrace{\begin{bmatrix} 
	  	x_4 \\ x_3 \\ x_2 \\ x_1
	   \end{bmatrix}}_{\bm{\lambda}}
\end{equation}
with
\begin{equation}
\underbrace{\begin{bmatrix} 
x_4(0) \\ x_3(0) \\ x_2(0) \\ x_1(0) 
\end{bmatrix}}_{{\bm{\lambda}}_0}
=
\begin{bmatrix}
	- \Delta\omega (\Delta\omega^2 + \omega_1^2) \, I_y \\
	-\Delta\omega \, (\Delta\omega \, I_x - \omega_1 I_z)  \\
	\Delta \omega \, I_y \\
	I_x 
\end{bmatrix}
\end{equation}
Solving these coupled equations, we obtain Eq.~\ref{Eq:example4-soln} for $x_1 = \rho(t)$.  
What about Example 5?  In this case we have simply
\begin{equation}
\bm{\Omega} = 
  \begin{bmatrix}
  0 & 0 & 0 & 0 \\
  1 & 0 & 0 & 0 \\
  0 & 1 & 0 & 0 \\
  0 & 0 & 1 & 0
  \end{bmatrix}
\text{ and }
{\bm{\lambda}}_0 = 
  \begin{bmatrix}
  0 \\ 0 \\ -\delta x \\ x
  \end{bmatrix}
\end{equation}
Solving these equations, we recover Eq.~\ref{eq:translate-x}, the expected result.

In the above equations we have defined $\bm{\lambda}$ as the vector of $x_n$'s that we are interested in and $\bm{\Omega}$ as the matrix of coefficients coupling $\bm{\lambda}$ to $\dot{\bm{\lambda}}$.  The coupled equations are summarized as
\begin{equation}
\frac{d \bm{\lambda}}{d t} 
	- \bm{\Omega} \cdot \bm{\lambda} 
	= 0
	\label{Eq:big-equation}
\end{equation} 
with $\bm{\lambda}_0$ given.  

The \VerbFcn{Evolver1} algorithm proceeds as follows.

\begin{enumerate}

  \item Evaluate the derivatives $\rho^{(1)}$ through $\rho^{(3)}$ by repeatedly applying computing $\rho^{(n+1)} = [-i H, \rho^{(n)}]$, starting from $\rho^{(0)} = \rho(0)$.  Assign the initial-condition vector ${\bm{\lambda}}_0 = (\rho^{(3)}, \ldots, \rho^{(0)})$.
  
  \item Fill in the lower 3 rows of $\bm{\Omega}$ by placing a $1$ in entries one below the diagonal and $0$ in all the other positions.
  
  \item  Look for an entry in the list $(\rho^{(2)}, \rho^{(1)}, \rho^{(0)})$ that is proportional to $\rho^{(3)}$, starting with the $\rho^{(2)}$ (entry $n = 3$) and working towards $\rho^{(0)}$ (entry $n = 1$). Call the entry where the match occurs $n_{\text{match}}$. Call the ratio between $\rho^{(3)}$ and the matching entry $r$.
  
  \item Fill in the upper row of $\bm{\Omega}$ with zeros.  Assign the value $r$ to the entry in the $n_{\text{match}}$ column of the upper row of $\bm{\Omega}$, counting from the right to the left.  
If no match can be found, declare the problem unsolvable.
  
  \item Feed Eq.~\ref{Eq:big-equation}, including the initial condition, to \emph{Mathematica} to solve.  The time-dependent density operator is $\rho(t) = \lambda_{1}(t)$. 

\end{enumerate}
	
% --------------------------	
\subsection{Method 5} 
% --------------------------	

An alternative approach is to identify, on a case-by-case basis, which differential equation $\rho(t)$ is governed by and write out the differential-equation solution by hand.
This alternative approach constitutes the \VerbFcn{Evolver2} algorithm. 
The algorithm proceeds by testing the following cases, stopping if the case is true.
The cases are labelled 0, 1, 2, or 3, according the order of differential equation governing $\rho$, and are given the designation L for linear and E for exponential, depending on the kind of solution. 

\begin{enumerate}

\item As above, evaluate the derivatives $\rho^{(1)}$ through $\rho^{(3)}$ .

\item (Case 0) If $\rho^{(1)} = 0$ then the Hamiltonian commutes with the initial density operator and
\begin{equation}
\rho(t) = \rho(0)
\end{equation}

\item (Case 1L) If $[\rho^{(1)}, H] = 0$ then
\begin{equation}
\rho(t) = \rho^{(0)} + \rho^{(1)} t
\end{equation}

\item Compute $c_1 =  \rho^{(1)}$ and the commutators 
\begin{subequations}
\begin{align}
c_2 &= [\rho^{(0)}, \rho^{(1)}] \\
c_3 &= [\rho^{(0)}, \rho^{(2)}] \\
c_4 &= [\rho^{(1)}, \rho^{(3)}]
\end{align}
\end{subequations}

\item Compute the ratios
\begin{subequations}
\begin{align} 
d_1 = {\mathrm{Inv}}[\rho^{(0)}] \, \rho^{(1)} \\
d_2 = {\mathrm{Inv}}[\rho^{(0)}] \, \rho^{(2)} \\
d_3 = {\mathrm{Inv}}[\rho^{(1)}] \, \rho^{(3)}
 \end{align}
\end{subequations}

\item (Case 1E) If $c_2 = 0$ then
\begin{equation}
\rho(t) = 
  e^{d_1 t} \rho^{(0)}
\end{equation}  

\item (Case 2E) If $c_3 = 0$ then define $\omega = \sqrt{-d_2}$ and compute
\begin{equation}
\rho(t) = 
  \cos{(\omega \, t)} \, \rho^{(0)}
  + \frac{1}{\omega} \sin{(\omega \, t)} \, c_1
\end{equation}

\item (Case 3E) If $c_4 = 0$ then define $\omega = \sqrt{-d_3}$ and compute
\begin{equation}
\rho(t) = 
  \rho^{(0)}
  + \frac{1}{\omega} \sin{(\omega \, t)} \, \rho^{(1)} 
  + \frac{1}{\omega^2} \left( 1 -  \cos{(\omega \, t)} \right) \, \rho^{(2)} 
\end{equation}

\item If none of these cases are satisfied, declare the problem unsolvable.

\end{enumerate}

% --------------------	
\subsection{Code} 
\label{sec:code}
% --------------------

To automate the steps in the \VerbFcn{Evolver1} and \VerbFcn{Evolver2} algorithms we require the ability to
\begin{enumerate}
  \item perform non-commutative algebra, 
  \item evaluate commutators,
  \item divide operators, and 
  \item determine which differential equation an evolved operator satisfies.
\end{enumerate}
\emph{Mathematica} has a native function for carrying out non-commutative multiplication, but this function has essentially no simplification rules associated with it.
For example,
\begin{Verbatim}[xleftmargin=0.25in]
In[1] := a ** (2 b) // Simplify
Out[1] = a ** (2 b)
\end{Verbatim}
This limitation was resolved by Helton and co-workers, whose \verb+NCALgebra+ package \cite{Helton2015feb} gives \emph{Mathematica} the ability to manipulate non-commuting algebraic expressions.
Their package allows the user to define variables as either commuting (e.g., $\omega$) or non-commuting (e.g., $I_+$, $I_x$, $a^{\dagger}$, and so on). 
The \verb+NCALgebra+ package forms an excellent starting point for implementing non-commutative multiplication, and expanding and simplifying commutators. 
We find, however, that using the package adds significant computational overhead, increasing computation time over ten-fold.  

To avoid this overhead, we created our own non-commutative multiplication and commutator functions, with accompanying simplification rules.

The resulting code consists of  \emph{Mathematica} files (\verb+.m+) and notebooks (\verb+.nb+).
Each modular \verb+m+ file implements a desired function.
Associated with each \verb+m+ file is a second \verb+m+ file containing \emph{unit tests}.
The code, at the time of writing, includes 160 unit tests.
Code was written in the literate-programming style \cite{Knuth1984feb}, with \LaTeX{}-style text, equations, and tables interspersed with code in the form of commented-out text.
The code and units tests are printed out, with typeset in-line commentary, in Appendix~\ref{sec:code}. 

To unit-test \verb+Evolver1+ and \verb+Evolver2+ algorithms, we computed the following rotating-frame unitary evolutions and checked the results against by-hand computations:
\begin{enumerate}
\item $e^{-i\omega t I_z } I_x e^{+i \omega t I_z}$,  
free evolution of transverse magnetization in a magnetic field
\item $e^{-i \omega t I_x} I_z e^{+i \omega t I_x}$,
on-resonance nutation of longitudinal (i.e., thermal-equilibrium) magnetization in the rotating frame
\item $e^{-i \omega t I_z} I_{+} e^{+i \omega t I_z}$,
free evolution of complex transverse magnetization in a magnetic field 
\item $e^{-i d t I_z S_z} I_x e^{+i d t I_z S_z}$,
evolution of transverse magnetization under a scalar coupling
\item $e^{-i (\Delta \, I_z + \omega \, I_x) t} I_z e^{+i (\Delta \, I_z + \omega \, I_x) t}$, off-resonance nutation of longitudinal magnetization \label{item:nutation}
\item $e^{- \omega t \frac{1}{2} (a^{\dagger} \, a + a \, a^{\dagger})} a e^{+ \omega t \frac{1}{2} (a^{\dagger} \, a + a \, a^{\dagger})}$,
evolution of the lowering (and raising) operator under the harmonic oscillator Hamiltonian
\item $e^{- \omega t \frac{1}{2} (a^{\dagger} \, a + a \, a^{\dagger})} Q e^{+ \omega t \frac{1}{2} (a^{\dagger} \, a + a \, a^{\dagger})}$,
evolution of the position (and momentum) operator under the harmonic oscillator Hamiltonian
\item $e^{-i \delta q \, P }  Q e^{+i \delta q \, P }$, a displacement
\item $e^{-i \delta q \, Q }  P e^{+i \delta q \, Q }$, a momentum kick
\end{enumerate}
The off-resonance spin nutation, case~\ref{item:nutation},  is an especially demanding test because it generates terms involving $I_x$, $I_y$, and $I_z$ operators from solutions to a third-order differential equation.

For unitary rotation involving spin and harmonic-oscillator operators, \verb+Evolver1+ and \verb+Evolver2+ give identical answers.
For the off-resonance Rabi nutation calculation, Example 5, the \verb+Evolver2+ algorithm is a factor of 25 faster than the \verb+Evolver1+ algorithm.

In the following section we present representative results.
Detailed applications of the code are given in seven stand-alone \emph{Mathematica} notebooks.
